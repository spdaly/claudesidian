# Small Language Models Are the Future of Agentic AI

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/media/reader/parsed_document_assets/317245954/-Gl-SLIOlBwp1HZOoobbbGbhkfUpJWIJ-_etlRyJ8QM-cove_wPwGRca.png)
<br>
>[!note]- Readwise Information
>Title:: Small Language Models Are the Future of Agentic AI
>Author:: [[Peter Belcak, Greg Heinrich, Shizhe Diao, Yonggan Fu, Xin Dong, Saurav Muralidharan, Yingyan Celine ...]]
>Type:: #Readwise/category/articles
>Published-Date:: [[2025-06-02]]
>Last-Highlighted-Date:: [[2025-09-07]]
>Readwise-Link:: https://readwise.io/bookreview/54824501
>Readwise-Source:: #Readwise/source/reader
>Source URL:: https://arxiv.org/pdf/2506.02153
--- 

## Linked Notes
```dataview
LIST
FROM [[Small Language Models Are the Future of Agentic AI by Peter Belcak, Greg Heinrich, Shizhe Diao, Yonggan Fu, Xin Dong, Saurav Muralidharan, Yingyan Celine ... Highlights]]
```

---

## Highlights
- We assert that the dominance of LLMs in the design of AI agents is both excessive and misaligned with the functional demands of most agentic use cases. While LLMs offer impressive generality and conversational fluency, the majority of agentic subtasks in deployed agentic systems are repetitive, scoped, and non-conversational—calling for models that are efficient, predictable, and inexpensive. In this context, SLMs not only suffice, but are often preferable. They offer several advantages: lower latency, reduced memory and computational requirements, and significantly lower operational costs, all while maintaining adequate task performance in constrained domains [View Highlight](https://readwise.io/open/935389972) ^rw935389972
- We argue that insisting on LLMs for all such tasks reflects a misallocation of computational resources—one that is economically inefficient and environmentally unsustainable at scale. [View Highlight](https://readwise.io/open/935389996) ^rw935389996
