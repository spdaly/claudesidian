# Understand Retrieval Augmented Generation (RAG) with Azure OpenAI Service - Training | Microsoft Learn

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/media/uploaded_book_covers/profile_174804/open-graph-image_pgRrhtV.png)
<br>
>[!note]- Readwise Information
>Title:: Understand Retrieval Augmented Generation (RAG) with Azure OpenAI Service - Training | Microsoft Learn
>Author:: [[ivorb]]
>Type:: #Readwise/category/articles
>Published-Date:: [[2023-08-08]]
>Last-Highlighted-Date:: [[2024-11-08]]
>Readwise-Link:: https://readwise.io/bookreview/45709028
>Readwise-Source:: #Readwise/source/reader
>Source URL:: https://learn.microsoft.com/en-us/training/modules/use-own-data-azure-openai/2-understand-use-own-data
--- 

## Linked Notes
```dataview
LIST
FROM [[Understand Retrieval Augmented Generation (RAG) with Azure OpenAI Service - Training | Microsoft Learn by ivorb Highlights]]
```

---

## Highlights
- RAG with Azure OpenAI allows developers to use supported AI chat models that can reference specific sources of information to ground the response. Adding this information allows the model to reference both the specific data provided and its pretrained knowledge to provide more effective responses. [View Highlight](https://readwise.io/open/809512043) ^rw809512043
- Fine-tuning is a technique used to create a custom model by training an existing foundational model such as `gpt-35-turbo` with a dataset of additional training data. [View Highlight](https://readwise.io/open/809512323) ^rw809512323
- ine-tuning can result in higher quality requests than prompt engineering alone, customize the model on examples larger than can fit in a prompt, and allow the user to provide fewer examples to get the same high quality response. [View Highlight](https://readwise.io/open/809513566) ^rw809513566
- the process for fine-tuning is both costly and time intensive, and should only be used for use cases where it's necessary [View Highlight](https://readwise.io/open/809513586) ^rw809513586
