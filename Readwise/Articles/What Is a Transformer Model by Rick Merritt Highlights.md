# What Is a Transformer Model?

![rw-book-cover](https://blogs.nvidia.com/wp-content/uploads/2022/03/Transformer-rbm2-x1280.jpg)
<br>
>[!note]- Readwise Information
>Title:: What Is a Transformer Model?
>Author:: [[Rick Merritt]]
>Type:: #Readwise/category/articles
>Published-Date:: [[2022-03-25]]
>Last-Highlighted-Date:: [[2025-02-06]]
>Readwise-Link:: https://readwise.io/bookreview/29347974
>Readwise-Source:: #Readwise/source/reader
>Source URL:: https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/
--- 

## Linked Notes
```dataview
LIST
FROM [[What Is a Transformer Model? by Rick Merritt Highlights]]
```

---

## Highlights
- What Is a Transformer Model?
  A transformer model is a neural network that learns context and thus meaning by tracking relationships in sequential data like the words in this sentence. [View Highlight](https://readwise.io/open/552546295) ^rw552546295
- Stanford researchers called transformers “foundation models” in an [August 2021 paper](https://arxiv.org/pdf/2108.07258.pdf) because they see them driving a paradigm shift in AI. The “sheer scale and scope of foundation models over the last few years have stretched our imagination of what is possible,” they wrote. [View Highlight](https://readwise.io/open/552546337) ^rw552546337 
- See also: [[foundational models]] 
- Transformers are translating text and speech in near real-time, opening meetings and classrooms to diverse and hearing-impaired attendees. [View Highlight](https://readwise.io/open/552546352) ^rw552546352
- Any application using sequential text, image or video data is a candidate for transformer models. [View Highlight](https://readwise.io/open/552546375) ^rw552546375
- **Transformers Replace CNNs, RNNs**
  Transformers are in many cases replacing convolutional and recurrent neural networks (CNNs and RNNs), the most popular types of deep learning models just five years ago. [View Highlight](https://readwise.io/open/552546479) ^rw552546479
- Before transformers arrived, users had to train neural networks with large, labeled datasets that were costly and time-consuming to produce. By finding patterns between elements mathematically, transformers eliminate that need, making available the trillions of images and petabytes of text data on the web and in corporate databases. [View Highlight](https://readwise.io/open/552546491) ^rw552546491 
- See also: [[ai]] 
- Note: Labeling of source datasets was labor intensive and created hurdles to the adopting of AI
