# How Large Language Models and Knowledge Graphs Can Transform Enterprise Search

![rw-book-cover](https://emtemp.gcom.cloud/ngw/globalassets/gartner-tile.jpg)
<br>
>[!note]- Readwise Information
>Title:: How Large Language Models and Knowledge Graphs Can Transform Enterprise Search
>Author:: [[Gartner]]
>Type:: #Readwise/category/articles
>Published-Date:: [[2023-03-28]]
>Last-Highlighted-Date:: [[2024-07-24]]
>Readwise-Link:: https://readwise.io/bookreview/41568023
>Readwise-Source:: #Readwise/source/reader
>Document-Tags:: [[knowledge graphs]] [[large language models]] 
>Source URL:: https://www.gartner.com/document/4218899?ref=authrightrec&refval=5415263
--- 

## Linked Notes
```dataview
LIST
FROM [[How Large Language Models and Knowledge Graphs Can Transform Enterprise Search by Gartner Highlights]]
```

---

## Highlights
- Search users expect answers to questions, not lists of links to resources that might contain the answers. Application technical professionals can use large language models and knowledge graphs to transform enterprise search to meet these demands. [View Highlight](https://readwise.io/open/734980372) ^rw734980372
- Large language models (LLMs), such as Generative Pretrained Transformer (GPT), Bidirectional Encoder Representations from Transformers (BERT) and Language Model for Dialogue Applications (LaMDA), used in conjunction with knowledge graphs, are key to providing modern search capabilities. [View Highlight](https://readwise.io/open/734982428) ^rw734982428
- An LLM is a specialized type of artificial intelligence (AI) that has been trained on vast amounts of text, typically billions of words, resulting in tens (or hundreds) of billions of parameters. This enables an LLM both to interpret textual input and generate human-like textual output. In other words, an LLM can help a search engine understand a question and formulate an answer. [View Highlight](https://readwise.io/open/734982660) ^rw734982660
- A vector embedding is a fixed-length, high-dimensional, numeric representation of a data item that captures its features. In other words, a vector embedding is a list of numbers that captures something’s meaning and context. Vector embeddings are simple to generate from a pretrained model, requiring only a few lines of code. [View Highlight](https://readwise.io/open/734982682) ^rw734982682
- This approach works on any type of data — including audio, images, video and so on — and is not restricted to text. Determining how closely related two things are is a matter of measuring the distance between their vectors. The best match for some vectors is basically the approximate nearest neighbor (ANN). This is particularly useful for search. [View Highlight](https://readwise.io/open/734982790) ^rw734982790
- Vector search treats content *semantically* by using vector embeddings of both the query and the content to be searched to account for the meanings of terms and the relationships between concepts. [View Highlight](https://readwise.io/open/734983020) ^rw734983020
- Generating vector embeddings is a critical step in this process as deep-learning models, central to modern search, do not directly utilize unstructured content. That content must first be converted to a numeric form or vector. When both a query and the content to be searched are vectorized, finding the right answer boils down to finding the query vector’s nearest neighbor in the vectorized corpus. This enables better queries, more precise search, and much richer and more accurate answers. [View Highlight](https://readwise.io/open/734983065) ^rw734983065
- Feature engineering relies on domain knowledge to identify, extract and encode salient characteristics of data. This approach can be applied to specialized areas, such as medical imaging or fraud detection, but is too dependent on human expertise and does not scale. [View Highlight](https://readwise.io/open/734983121) ^rw734983121
- A better approach is to use pretrained embeddings generated by models such as [word2vec](https://arxiv.org/abs/1301.3781) for text or [VGG](https://arxiv.org/abs/1409.1556) for images. A wide range of such models for an equally wide range of data types is available at the [Hugging Face](https://huggingface.co/models) model hub. A drawback of this approach is that the character and context of the data being vectorized is limited to what is explicitly present in the corpus being processed and the features used to train the model. A better approach is to use an LLM trained on a radically larger dataset to generate vector embeddings. [View Highlight](https://readwise.io/open/734983124) ^rw734983124
- In a similar way, LLMs can generate much richer vector embeddings than simpler, more limited pretrained models (see Figure 3). A vector generated by a model trained on a specific corpus, such as enterprise content, will typically incorporate several hundred descriptive dimensions. While this may seem impressive, a vector generated by an LLM will have access to several *billion* descriptive dimensions. [View Highlight](https://readwise.io/open/734983856) ^rw734983856
- The ontology governing a particular knowledge graph provides an additional capability unavailable in other approaches to data management. [View Highlight](https://readwise.io/open/749935385) ^rw749935385
- If feature engineering, based on domain expertise, does not scale and general-purpose LLMs lack the necessary expertise, how do we get the benefits of applying LLMs to search without the costly and embarrassing mistakes they may introduce? [View Highlight](https://readwise.io/open/734984286) ^rw734984286
- The answer is to utilize LLMs trained in the specific domain of the search application. [View Highlight](https://readwise.io/open/734984292) ^rw734984292
- Creating *enterprise-specific*variations of generalized LLMs still requires expertise and resources beyond the reach of many, if not most, organizations. Vendors are beginning to offer LLM development services to meet this need. [View Highlight](https://readwise.io/open/734984346) ^rw734984346
- The hurdles to creating purpose-built, domain-specific LLMs or customizing generalized LLMs are beginning to fall. Google researchers have recently published a method called SKILL (Structured Knowledge Infusion for Large Language Models) for training models on domain-specific information. LLMs developed with SKILL have demonstrated threefold improvement on search tasks. [View Highlight](https://readwise.io/open/734984376) ^rw734984376
- This idea of searching for “things not strings” is the key to effective, answer-oriented search, and knowledge graphs, used in conjunction with LLMs, are what make it possible both for Google and enterprises. [View Highlight](https://readwise.io/open/734984486) ^rw734984486
- Knowledge graphs are machine-readable data structures. They represent knowledge of the physical and digital worlds, including entities (people, organizations, digital assets and so on) and the relationships between them. These entities and relationships adhere to a graph data model, which is a network of nodes (vertices) and links (edges/arcs). The entities and relationships allowed in the knowledge graph are defined in an ontology, which is a formal model of the domain being represented. [View Highlight](https://readwise.io/open/734984515) ^rw734984515
- These models consist of numerous three-part (or in some cases four-part) statements in the form “subject, predicate, object,” such as “Person,” “hasName,” “Name.” [View Highlight](https://readwise.io/open/734984531) ^rw734984531
- An ontology defines which entities are allowed and how they relate to each other. Ontologies are usually defined and represented using a standard such as Resource Description Framework (RDF), Terse RDF Triple Language (TURTLE), Simple Knowledge Organization System (SKOS) or Web Ontology Language (OWL) [View Highlight](https://readwise.io/open/734984586) ^rw734984586
- A knowledge graph is an instantiation of an ontology, using the definition to represent actual entities and their relationships. A knowledge graph consists of the instance data mapped to the ontology (see Figure 4). [View Highlight](https://readwise.io/open/734985211) ^rw734985211
- The ontology governing a particular knowledge graph provides an additional capability unavailable in other approaches to data management. Information not explicitly present in the dataset can be inferred. [View Highlight](https://readwise.io/open/734985942) ^rw734985942
- This ability to infer facts and represent meaningful entities and relationships is extraordinarily powerful in the context of search. [View Highlight](https://readwise.io/open/734985856) ^rw734985856
- Once defined, mapping and maintaining data sources can require fundamental changes to enterprise data management procedures and policies. [View Highlight](https://readwise.io/open/734985989) ^rw734985989
- Users struggle to articulate their information need clearly and adequately. This is true whether they formulate that need as questions or queries (keywords and operators) [View Highlight](https://readwise.io/open/734987165) ^rw734987165
- Query expansion is not a new technique. Comparing search keywords to a thesaurus and adding synonyms to the query is a common way to reconcile terminology between users and content. [View Highlight](https://readwise.io/open/734987189) ^rw734987189
- If additional terms in the query or question are related to PTO in a knowledge graph — “trainers,” “filing” or “vacation,” for example — the intended meaning becomes much more apparent. This also allows us to add important related concepts to the query before it is issued, such as “noncompete clause.” [View Highlight](https://readwise.io/open/734987362) ^rw734987362
- Knowledge graphs enhance enterprise search platforms and insight engines, but cannot replace them. [View Highlight](https://readwise.io/open/734988134) ^rw734988134
- Extracting meaningful, indexable information from text is a complicated and messy task [View Highlight](https://readwise.io/open/734988329) ^rw734988329
- By 2024, companies that use graphs and semantic approaches for natural language technology projects will have 75% less artificial intelligence technical debt than those that do not. [View Highlight](https://readwise.io/open/734988314) ^rw734988314
