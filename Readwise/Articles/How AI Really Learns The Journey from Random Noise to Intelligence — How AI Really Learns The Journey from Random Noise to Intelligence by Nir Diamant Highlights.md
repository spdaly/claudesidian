# How AI Really Learns: The Journey from Random Noise to Intelligence
How AI Really Learns: The Journey from Random Noise to Intelligence

![rw-book-cover](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7731cfa7-fc73-473b-bb49-fabac7432086_1792x1024.png)
<br>
>[!note]- Readwise Information
>Title:: How AI Really Learns: The Journey from Random Noise to Intelligence
How AI Really Learns: The Journey from Random Noise to Intelligence
>Author:: [[Nir Diamant]]
>Type:: #Readwise/category/articles
>Published-Date:: [[2024-12-24]]
>Last-Highlighted-Date:: [[2024-12-25]]
>Readwise-Link:: https://readwise.io/bookreview/47111751
>Readwise-Source:: #Readwise/source/reader
>Document-Tags:: [[Artificial Intelligence]] [[Large Language Models]] 
>Source URL:: https://diamantai.substack.com/p/how-ai-really-learns-the-journey?r=336pe4&utm_campaign=post&utm_medium=web&triedRedirect=true
--- 

## Linked Notes
```dataview
LIST
FROM [[How AI Really Learns: The Journey from Random Noise to Intelligence
How AI Really Learns: The Journey from Random Noise to Intelligence by Nir Diamant Highlights]]
```

---

## Highlights
- The model also learns to understand context in increasingly sophisticated ways. For instance, when it sees "The cat sat on the mat because..." it's not just learning about cats and mats—it's learning about causality, the relationship between tiredness and sitting, and the typical behaviors of animals. [View Highlight](https://readwise.io/open/829080100) ^rw829080100
- When the model makes a prediction, we can calculate not just how wrong it was, but exactly how each of its billions of parameters contributed to that wrongness. Imagine having a measure of wrongness (we call this the "loss function") that's like a compass pointing us in the direction of better predictions. [View Highlight](https://readwise.io/open/829080201) ^rw829080201
- This technique (which researchers call "backpropagation") lets us figure out exactly which parts of the model contributed to the mistake. [View Highlight](https://readwise.io/open/829080659) ^rw829080659
- Note: In your last reading session, you explored how AI models, starting as random noise with billions of parameters, undergo training through a prediction game where they attempt to fill in missing words in sentences. This process enables the model not only to learn language patterns but also to understand context and relationships, akin to a newborn learning to communicate, with the ability to measure its errors through the loss function and adjust accordingly using backpropagation.
- This is called curriculum learning, and it's remarkably similar to how we structure human education. [View Highlight](https://readwise.io/open/829080959) ^rw829080959
- As training progresses, something remarkable happens. The model begins to exhibit behaviors that go beyond simple pattern matching. It starts to show signs of what we might call "emergent abilities"—capabilities that weren't explicitly trained for but arise from the complex interactions of all its learned patterns. [View Highlight](https://readwise.io/open/829082226) ^rw829082226
