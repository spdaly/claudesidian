# Race to AI: The Origins of Artificial Intelligence, From Turing to ChatGPT

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/media/uploaded_book_covers/profile_174804/5000.jpg)
<br>
>[!note]- Readwise Information
>Title:: Race to AI: The Origins of Artificial Intelligence, From Turing to ChatGPT
>Author:: [[Ian Sample]]
>Type:: #Readwise/category/articles
>Published-Date:: [[2023-10-28]]
>Last-Highlighted-Date:: [[2024-01-18]]
>Readwise-Link:: https://readwise.io/bookreview/36797342
>Readwise-Source:: #Readwise/source/reader
>Source URL:: https://www.theguardian.com/technology/2023/oct/28/artificial-intelligence-origins-turing-to-chatgpt
--- 

## Linked Notes
```dataview
LIST
FROM [[Race to AI: The Origins of Artificial Intelligence, From Turing to ChatGPT by Ian Sample Highlights]]
```

---

## Highlights
- The engine at the heart of generative AI is known as a transformer. Developed by Google researchers, originally to improve translation, it was described in a 2017 paper whose title, Attention Is All You Need, riffs on a Beatles hit. Even its creators seem to have underestimated the impact it would have. [View Highlight](https://readwise.io/open/662859235) ^rw662859235
- Before the transformer, AI-driven translators typically learned language by processing sentences one word after another. The approach has its drawbacks. Processing words in sequence is slow, and it doesnâ€™t work well for long sentences: by the time the last words are reached, the first have been forgotten. The transformer solves these problems with help from a process called attention. It allows the network to process all the words in a sentence at once, and understand each word in the context of those around it. [View Highlight](https://readwise.io/open/662859198) ^rw662859198
