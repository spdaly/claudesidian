# How LLMs Game SWE-Bench Verified - by Benjamin Marie

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/media/uploaded_book_covers/profile_174804/https3A2F2Fsubstack-post-media.s3.amazonaws.com2Fpublic2Fimages2Fbd3f4615-2c66-4a1a-8e7c-7002fe563e0b_1517x849.png)
<br>
>[!note]- Readwise Information
>Title:: How LLMs Game SWE-Bench Verified - by Benjamin Marie
>Author:: [[Substack]]
>Type:: #Readwise/category/articles
>Published-Date:: [[2025-07-22]]
>Last-Highlighted-Date:: [[2025-09-08]]
>Readwise-Link:: https://readwise.io/bookreview/54846470
>Readwise-Source:: #Readwise/source/reader
>Document-Tags:: [[ai coding assistants]] 
>Source URL:: https://kaitchup.substack.com/p/how-llms-game-swe-bench-verified?utm_source=unread-posts-digest-email&inbox=true&utm_medium=email&triedRedirect=true
--- 

## Linked Notes
```dataview
LIST
FROM [[How LLMs Game SWE-Bench Verified - by Benjamin Marie by Substack Highlights]]
```

---

## Highlights
- SWE-Bench Verified has leakage paths that let agents peek at the repo’s **future state**, so they can effectively “see the answer” before solving. So, they get higher scores not because they can code a solution, but because they can find the solution in the repository… [View Highlight](https://readwise.io/open/935687757) ^rw935687757
- Note: SWE-Bench Verified is a flawed assessment score due to the nature of LLMs
- Unsloth’s latest RL update extends usable context length by about 1.2–1.7x without extra memory or slowdown and trims RL wall-clock by ~10% via kernel optimizations and asynchronous data movement, while halving torch.compile latency during model load (≈2× faster). [View Highlight](https://readwise.io/open/935687950) ^rw935687950 
- See also: [[reinforcement learning human feedback]] [[unsloth]] 
