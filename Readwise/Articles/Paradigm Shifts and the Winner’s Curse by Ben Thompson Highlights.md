# Paradigm Shifts and the Winner’s Curse

![rw-book-cover](https://i0.wp.com/stratechery.com/wp-content/uploads/2025/08/paradigms-2.png?fit=1200%2C900&ssl=1)
<br>
>[!note]- Readwise Information
>Title:: Paradigm Shifts and the Winner’s Curse
>Author:: [[Ben Thompson]]
>Type:: #Readwise/category/articles
>Published-Date:: [[2025-08-06]]
>Last-Highlighted-Date:: [[2025-08-06]]
>Readwise-Link:: https://readwise.io/bookreview/53982647
>Readwise-Source:: #Readwise/source/reader
>Source URL:: https://stratechery.com/2025/paradigm-shifts-and-the-winners-curse/?access_token=eyJhbGciOiJSUzI1NiIsImtpZCI6InN0cmF0ZWNoZXJ5LnBhc3Nwb3J0Lm9ubGluZSIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJzdHJhdGVjaGVyeS5wYXNzcG9ydC5vbmxpbmUiLCJhenAiOiJIS0xjUzREd1Nod1AyWURLYmZQV00xIiwiZW50Ijp7InVyaSI6WyJodHRwczovL3N0cmF0ZWNoZXJ5LmNvbS8yMDI1L3BhcmFkaWdtLXNoaWZ0cy1hbmQtdGhlLXdpbm5lcnMtY3Vyc2UvIl19LCJleHAiOjE3NTcwODY5MjAsImlhdCI6MTc1NDQ5NDkyMCwiaXNzIjoiaHR0cHM6Ly9hcHAucGFzc3BvcnQub25saW5lL29hdXRoIiwic2NvcGUiOiJmZWVkOnJlYWQgYXJ0aWNsZTpyZWFkIGFzc2V0OnJlYWQgY2F0ZWdvcnk6cmVhZCBlbnRpdGxlbWVudHMiLCJzdWIiOiI5NGYyNTY1YS0xZTJkLTQ5YzUtYTlhNi0wYmViMzU1YjFmNTAiLCJ1c2UiOiJhY2Nlc3MifQ.NKtIN2dpuVPlUXPWoMzr3GAYljgR80EHKckedAszM_jAtsQepDNry2fhI-TkVRsIcDeB1K4EWU8aRB0D95hkzP1h3J3Y3YSz8WEQ4h5bplj9Wf0U9PLdRVMgw5w87bSfiExUdx4XFTaTipCSh-szgdr28Yr2MQlVjis8TTV_VKGPmJElXc-KwqX75Nhn-qW8j_-DHhq0ewN6-8ZHKPLDA4f7HQShTJj8qOQfsRMqq9aXLGIHkNF8AWgtKBGq4bnq7qo-h-eHFC0DNATq2xEu152U4rGzh9Y7nZKprdaPfuTslOpNYVlL-S-m0dHVUqClRww6I9cHxEo3KHylf5vO0A
--- 

## Linked Notes
```dataview
LIST
FROM [[Paradigm Shifts and the Winner’s Curse by Ben Thompson Highlights]]
```

---

## Highlights
- Andy Jassy:
  > The first thing I would say is that I think it is so early right now in AI. If you look at what’s really happening in the space, it’s very top heavy. So you have a small number of very large frontier models that are being trained that spend a lot on computing, a couple of which are being trained on top of AWS and others are being trained elsewhere. And then you also have, I would say, a relatively small number of very large-scale generative AI applications. [View Highlight](https://readwise.io/open/923071579) ^rw923071579
- Andy Jassy:
  > People aren’t paying as close attention as they will and making sure that those generative AI applications are operating where the rest of their data and infrastructure. Remember, a lot of generative AI inference is just going to be another building block like compute, storage and database. And so people are going to actually want to run those applications close to where the other applications are running, where their data is. There’s just so many more applications and data running in AWS than anywhere else. [View Highlight](https://readwise.io/open/923073060) ^rw923073060
- **Apple:** *Large language models are useful, but will be a commodity, and easily accessible on your iPhone; what is the most useful to people, however, is AI that has your private data as context, and only we can provide that. We will provide AI with your data as context at scale and at low cost — both in terms of CapEx and OpEx — by primarily running inference on device. People are also concerned about sharing their personal data with AI companies, so when we need more capabilities we will use our own compute infrastructure, which will run on our own chips, not Nvidia chips.* [View Highlight](https://readwise.io/open/923073143) ^rw923073143
- **Amazon:** *Large language models are useful, but will be a commodity, and widely available on any cloud. What is the most useful to companies, however, is AI that has your enterprise data as context, and more enterprises are on AWS than anywhere else. We will provide AI with a company’s data as context at scale and at low cost — both in terms of CapEx and OpEx — by primarily running inference on our own AI chips, not Nvidia chips.* [View Highlight](https://readwise.io/open/923073155) ^rw923073155
