# Co-Intelligence

![rw-book-cover](https://m.media-amazon.com/images/I/913YN4MmhfL._SY160.jpg)
<br>
>[!note]- Readwise Information
>Title:: Co-Intelligence
>Author:: [[Ethan Mollick]]
>Type:: #Readwise/category/books
>Published-Date:: [[]]
>Last-Highlighted-Date:: [[2024-11-20]]
>Readwise-Link:: https://readwise.io/bookreview/47421269
>Readwise-Source:: #Readwise/source/kindle
--- 

## Linked Notes
```dataview
LIST
FROM [[Co-Intelligence by Ethan Mollick Highlights]]
```

---

## Highlights
- AI is what those of us who study technology call a General Purpose Technology (ironically, also abbreviated GPT). These advances are once-in-a-generation technologies, like steam power or the internet, that touch every industry and every aspect of life. And, in some ways, generative AI might even be bigger. General Purpose Technologies typically have slow adoption, as they require many other technologies to work well. [Location 113](https://readwise.io/open/833774979) ^rw833774979
- ChatGPT reached 100 million users faster than any previous product in history, driven by the fact that it was free to access, available to individuals, and incredibly useful. [Location 125](https://readwise.io/open/833774980) ^rw833774980
- Early studies of the effects of AI have found it can often lead to a 20 to 80 percent improvement in productivity across a wide variety of job types, from coding to marketing. By contrast, when steam power, that most fundamental of General Purpose Technologies, the one that created the Industrial Revolution, was put into a factory, it improved productivity by 18 to 22 percent. And despite decades of looking, economists have had difficulty showing a real long-term productivity impact of computers and the internet over the past twenty years. [Location 132](https://readwise.io/open/833774981) ^rw833774981
- The Transformer solved these issues by utilizing an “attention mechanism.” This technique allows the AI to concentrate on the most relevant parts of a text, making it easier for the AI to understand and work with language in a way that seemed more human. [Location 225](https://readwise.io/open/833774982) ^rw833774982
- The attention mechanism helps solve this problem by allowing the AI model to weigh the importance of different words or phrases in a block of text. [Location 232](https://readwise.io/open/833774983) ^rw833774983
- This is called pretraining, and unlike earlier forms of AI, it is unsupervised, which means the AI doesn’t need carefully labeled data. [Location 248](https://readwise.io/open/833774984) ^rw833774984
- The apprentice chef begins with a chaotic, disorganized pantry, representing the 175 billion weights. [Location 257](https://readwise.io/open/833774985) ^rw833774985
- Note: Good analogy on how a LLC learns
- Training an AI to do this is an iterative process, and requires powerful computers to handle the immense calculations involved in learning from billions of words. This pretraining phase is one of the main reasons AIs are so expensive to build. [Location 269](https://readwise.io/open/833774986) ^rw833774986
- the entire email database of Enron, shut down for corporate fraud, is used as part of the training material for many AIs, simply because it was made freely available to AI researchers. [Location 275](https://readwise.io/open/833774987) ^rw833774987
- The search for high-quality content for training material has become a major topic in AI development, since information-hungry AI companies are running out of good, free sources. [Location 277](https://readwise.io/open/833774988) ^rw833774988
- The legal implications of this are still unclear. Since the data is used to create weights, and not directly copied into the AI systems, [Location 280](https://readwise.io/open/833774989) ^rw833774989
- AI can also learn biases, errors, and falsehoods from the data it sees. [Location 287](https://readwise.io/open/833774990) ^rw833774990 
- See also: [[favorite]] 
- That feedback is then used to do additional training, fine-tuning the AI’s performance to fit the preferences of the human, providing additional learning that reinforces good answers and reduces bad answers, which is why the process is called Reinforcement Learning from Human Feedback (RLHF). [Location 295](https://readwise.io/open/833774991) ^rw833774991
- Professor Sam Bowman of New York University wrote of the neural networks underlying LLMs: “There are hundreds of billions of connections between these artificial neurons, some of which are invoked many times during the processing of a single piece of text, such that any attempt at a precise explanation of an LLM’s behavior is doomed to be too complex for any human to understand.” [Location 418](https://readwise.io/open/833774992) ^rw833774992
- Experts in the field of AI put the chance of an AI killing at least 10 percent of living humans by 2100 at 12 percent, while panels of expert futurists think the number is closer to 2 percent. [Location 481](https://readwise.io/open/833774993) ^rw833774993
- Few AI companies have asked for permission from content creators before using their data for training, and many of them keep their training data secret. [Location 508](https://readwise.io/open/833774994) ^rw833774994
- Even if pretraining is legal, it may not be ethical. Most AI companies do not ask for the permission of the people whose data they train on. [Location 516](https://readwise.io/open/833774995) ^rw833774995
- The complication is that AI does not really plagiarize, in the way that someone copying an image or a block of text and passing it off as their own is plagiarizing. [Location 520](https://readwise.io/open/833774996) ^rw833774996
- The fact that the material used for pretraining represents only an odd slice of human data (often, whatever the AI developers could find and assume was free to use) introduces another set of risks: bias. Part of the reason AIs seem so human to work with is that they are trained on our conversations and writings. So human biases also work their way into the training data. [Location 527](https://readwise.io/open/833774997) ^rw833774997
- The most common approach to reducing bias is for humans to correct the AIs, as in the Reinforcement Learning from Human Feedback (RLHF) process, which is part of the fine-tuning of LLMs that we discussed in the previous chapter. [Location 554](https://readwise.io/open/833774998) ^rw833774998
- You should try inviting AI to help you in everything you do, barring legal or ethical barriers. As you experiment, you may find that AI help can be satisfying, or frustrating, or useless, or unnerving. But you aren’t just doing this for help alone; familiarizing yourself with AI’s capabilities allows you to better understand how it can assist you—or threaten you and your job. Given that AI is a General Purpose Technology, there is no single manual or instruction book that you can refer to in order to understand its value and its limits. [Location 659](https://readwise.io/open/833774999) ^rw833774999
- AI is not a silver bullet, and there will be instances when it might not work as expected or may even produce undesirable outcomes. [Location 703](https://readwise.io/open/833775000) ^rw833775000
- For now, AI works best with human help, and you want to be that helpful human. As AI gets more capable and requires less human help—you still want to be that human. So the second principle is to learn to be the human in the loop. [Location 717](https://readwise.io/open/833775001) ^rw833775001
- Anthropomorphism is the act of ascribing human characteristics to something that is nonhuman. [Location 753](https://readwise.io/open/833775002) ^rw833775002
- Gary Marcus and Sasha Luccioni warn, “The more false agency people ascribe to them, the more they can be exploited.” [Location 761](https://readwise.io/open/833775003) ^rw833775003
- Thus, in the following chapters, when I say an AI “thinks,” “learns,” “understands,” “decides,” or “feels,” please remember that I’m speaking metaphorically. AI systems don’t have a consciousness, emotions, a sense of self, or physical sensations. [Location 769](https://readwise.io/open/833775004) ^rw833775004
- Traditional software is predictable, reliable, and follows a strict set of rules. When properly built and debugged, software yields the same outcomes every time. AI, on the other hand, is anything but predictable and reliable. [Location 846](https://readwise.io/open/833775005) ^rw833775005
- There’s no definitive guide on how to use AI in your organization. We’re all learning by experimenting, sharing prompts as if they were magical incantations rather than regular software code. [Location 854](https://readwise.io/open/833775006) ^rw833775006
- “Sparks of Artificial General Intelligence: Early Experiments with GPT-4.” [Location 1091](https://readwise.io/open/833775007) ^rw833775007
- There is no definitive answer to why LLMs hallucinate, and the contributing factors may differ among models. Different LLMs may have different architectures, training data, and objectives. But in many ways, hallucinations are a deep part of how LLMs work. They don’t store text directly; rather, they store patterns about which tokens are more likely to follow others. That means the AI doesn’t actually “know” anything. It makes up its answers on the fly. [Location 1170](https://readwise.io/open/833775008) ^rw833775008
- These small hallucinations are hard to catch because they are completely plausible. I was able to notice the issues only after an extremely close reading and research on every fact and sentence in the output. [Location 1214](https://readwise.io/open/833775009) ^rw833775009
- One such test is known as the Alternative Uses Test (AUT). This measures an individual’s ability to come up with a wide variety of uses for a common object. In this test, a participant is presented with an everyday object, such as a paper clip, and is asked to come up with as many different uses for the object as possible. [Location 1259](https://readwise.io/open/833775010) ^rw833775010
- The AUT is often used to evaluate an individual’s ability to think divergently and to come up with unconventional ideas. [Location 1262](https://readwise.io/open/833775011) ^rw833775011
- A popular one is the remote associates test (RAT). This test asks people to find the common word that connects a set of three seemingly unrelated words. For example, pine, crab, and sauce are connected by the word apple. (Try one: What word connects cream, skate, and water? The AI got it right.) Unsurprisingly, as a connection machine, AI usually maxes out this test, too. [Location 1282](https://readwise.io/open/833775012) ^rw833775012
- Participants who used ChatGPT saw a dramatic reduction in their time on tasks, slashing it by a whopping 37 percent. Not only did they save time, but the quality of their work also increased as judged by other humans. [Location 1384](https://readwise.io/open/833775013) ^rw833775013
- The study also showed that AI teammates helped reduce productivity inequality. Participants who scored lower on the first round without AI assistance benefited more from using ChatGPT, narrowing the gap between low and high scorers. [Location 1387](https://readwise.io/open/833775014) ^rw833775014
- To get the AI to do unique things, you need to understand parts of the culture more deeply than everyone else using the same AI systems. [Location 1424](https://readwise.io/open/833775015) ^rw833775015
- humanities majors can produce some of the most interesting “code.” [Location 1425](https://readwise.io/open/833775016) ^rw833775016
- Nick Cave [Location 1451](https://readwise.io/open/833775017) ^rw833775017
- Hayao Miyazaki [Location 1451](https://readwise.io/open/833775018) ^rw833775018
- Thanks to AI, their written materials no longer hold them back, and they get job offers off the strength of their experience and interviews. Since requiring AI in my classes, I no longer see badly written work at all. And as my students learn, if you work interactively with the AI, the outcome doesn’t feel generic, it feels like a human did [Location 1471](https://readwise.io/open/833775019) ^rw833775019
- There is already evidence that this is going to be a problem. The MIT study mentioned earlier found that ChatGPT mostly serves as a substitute for human effort, not a complement to our skills. In fact, the vast majority of participants didn’t even bother editing the AI’s output. This is a problem I see repeatedly when people first use AI: they just paste in the exact question they are asked and let the AI answer it. [Location 1486](https://readwise.io/open/833775020) ^rw833775020
- This kind of meaningless task, what organizational theorists have called mere ceremony, has always been with us. But AI will make a lot of previously useful tasks meaningless. It will also remove the facade that previously disguised meaningless tasks. We may not have always known if our work mattered in the bigger picture, but in most organizations, the people in your part of the organizational structure felt it did. With AI-generated work sent to other AIs to assess, that sense of meaning disappears. [Location 1508](https://readwise.io/open/833775021) ^rw833775021
